# V2X-AHD
This is the introduction of the essay "V2X-AHD: Vehicle-to-Everything Cooperation Perception via Asymmetric Heterogenous Distillation Network". Until now, the manuscript is under review, we will only upload the core code after the manuscript is accepted, and we will upload the whole rest structure. This code is based on the work of "V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer (ECCV 2022)", and the URL is https://github.com/DerrickXuNu/v2x-vit. We propose a brand new backbone called SparePillar based on spare convolution, after that, we leverage the distillation model and give the teacher and student model. On that basis, we extend the training form of the raw code, now, we can use parallel training with multi-GPU to save training time. 
